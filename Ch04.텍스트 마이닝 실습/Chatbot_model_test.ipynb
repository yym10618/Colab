{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/yym10618/Colab/blob/master/Ch04.%ED%85%8D%EC%8A%A4%ED%8A%B8%20%EB%A7%88%EC%9D%B4%EB%8B%9D%20%EC%8B%A4%EC%8A%B5/Chatbot_model_test.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qqv4HkNYJ6_T"
      },
      "outputs": [],
      "source": [
        "import tensorflow as tf\n",
        "import numpy as np\n",
        "import pickle\n",
        "from tensorflow.keras.models import load_model\n",
        "from tensorflow.keras.preprocessing.sequence import pad_sequences"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "llSB5KMhKNoK"
      },
      "outputs": [],
      "source": [
        "# 토큰 불러오기\n",
        "with open('/content/drive/MyDrive/파이썬 데이터 과학 실습/file/chatbot_tokenizer.pickle', 'rb') as handle:\n",
        "  tokenizer = pickle.load(handle)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 모델 불러오기\n",
        "model = load_model('/content/drive/MyDrive/파이썬 데이터 과학 실습/file/chatbot_model.h5')\n",
        "model"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6hYf-y46K4OT",
        "outputId": "6ca3c8d1-b34d-48e5-e60f-7081bac85fe0"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.engine.sequential.Sequential at 0x7f2c1e233350>"
            ]
          },
          "metadata": {},
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 문장 생성 함수\n",
        "def sentence_generation(current_word):\n",
        "  init_word = current_word\n",
        "  sentence = ''\n",
        "\n",
        "  while True:\n",
        "    encoded = tokenizer.texts_to_sequences([current_word])[0]\n",
        "    encoded = pad_sequences([encoded], maxlen=20, padding='pre')\n",
        "\n",
        "    # 입력한 X(현재 단어)에 대해서 y를 예측하고 y(예측한 단어)를 result에 저장\n",
        "    result = model.predict(encoded, verbose=0)\n",
        "    result = np.argmax(result, axis=1)\n",
        "\n",
        "    for word, index in tokenizer.word_index.items():\n",
        "      # 만약, 예측한 단어, 인덱스와 동일한 단어가 있다면\n",
        "      if index == result:\n",
        "        break\n",
        "\n",
        "    # 종료체크\n",
        "    if word == '<end>':\n",
        "      break\n",
        "\n",
        "    # 현재 단어 + ' ' + 예측 단어를 현재 단어로 변경\n",
        "    current_word = current_word + ' ' + word\n",
        "\n",
        "    # 예측 단어를 문장에 저장\n",
        "    sentence = sentence + ' ' + word\n",
        "\n",
        "  sentence = init_word + '--->' + sentence\n",
        "\n",
        "  return sentence"
      ],
      "metadata": {
        "id": "6ZOf3xuPK-eC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 테스트\n",
        "print(sentence_generation('12시 땡!'))\n",
        "print(sentence_generation('코 막혀'))\n",
        "print(sentence_generation('무슨 말을 해야할까'))\n",
        "print(sentence_generation('안녕'))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "B3mVzeINMfIb",
        "outputId": "fb57685b-f978-4a6d-d64f-c25823112bfe"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "12시 땡!---> 하루가 또 가네요\n",
            "코 막혀---> 감기 조심하세요\n",
            "무슨 말을 해야할까---> 하고 싶은 말 다하세요\n",
            "안녕---> 안녕하세요\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "JIxDZlICMqGh"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "collapsed_sections": [],
      "name": "Chatbot_model_test.ipynb",
      "provenance": [],
      "mount_file_id": "1poRGMxxTBwfrDxVPnhAYiaoQwrmRmwiU",
      "authorship_tag": "ABX9TyMpmbyLFpI2vprDGpHXHqP8",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}